{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 瞭解如何使用計數方法詞向量與SVD\n",
    "\n",
    "再將文字資料輸入模型進行自然語言任務之前，其中一項重要的前處理即為將字詞向量化(詞嵌入word embedding)。 而將詞向量化的方法有很多，這裡我們會著重在介紹如何使用計數方法來將字詞向量化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字詞前處理\n",
    "\n",
    "在進行字詞向量化之前，我們需要針對文本資料進行前置處理，將**文本資料分割成字詞(斷詞)**，再將分割後的**字詞轉換成字詞ID清單**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed corpus: [[6 2 0 5 1 2 3 4]] \n",
      " word2idx: {'goodbye': 0, 'i': 1, 'say': 2, 'hello': 3, '.': 4, 'and': 5, 'you': 6} \n",
      " idx2word: {0: 'goodbye', 1: 'i', 2: 'say', 3: 'hello', 4: '.', 5: 'and', 6: 'you'}\n"
     ]
    }
   ],
   "source": [
    "#導入會使用的library\n",
    "import re\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "#定義前處理函式\n",
    "def preprocess(corpus: List[str], only_word: bool = False):\n",
    "    '''Function to do preprocess of input corpus\n",
    "    Parameters\n",
    "    -----------\n",
    "    corpus: str\n",
    "        input corpus to be processed\n",
    "    only_word: bool\n",
    "        whether to filter out non-word\n",
    "    '''\n",
    "    word_dic = set()\n",
    "    processed_sentence = []\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        #將所有字詞轉為小寫\n",
    "        sentence = sentence.lower()\n",
    "\n",
    "        #移除標點符號(可以依據使用狀況決定是否要移除標點符號)\n",
    "        if only_word:\n",
    "            pattern = r'[^\\W_]+'\n",
    "            sentence = re.findall(pattern, sentence)\n",
    "        else:\n",
    "            punctuation_list = ['.', ',', '!', '?']\n",
    "            for pun in punctuation_list:\n",
    "                sentence = sentence.replace(pun, ' '+pun)\n",
    "            sentence = sentence.split(' ')\n",
    "        \n",
    "        #添加字詞到字典中\n",
    "        word_dic |= set(sentence)\n",
    "        processed_sentence.append(sentence)\n",
    "    \n",
    "    \n",
    "    #建立字詞ID清單\n",
    "    word2idx = dict()\n",
    "    idx2word = dict()\n",
    "    for word in word_dic:\n",
    "        if word not in word2idx:\n",
    "            idx = len(word2idx)\n",
    "            word2idx[word] = idx\n",
    "            idx2word[idx] = word\n",
    "\n",
    "    #將文本轉為ID型式\n",
    "    id_mapping = lambda x: word2idx[x]\n",
    "    \n",
    "    corpus = np.array([list(map(id_mapping, sentence)) for sentence in processed_sentence])\n",
    "\n",
    "    return corpus, word2idx, idx2word\n",
    "\n",
    "#定義簡易文本資料(使用Ch17講義中的例子)\n",
    "corpus = ['You say goodbye and I say hello.']\n",
    "\n",
    "processed_corpus, word2idx, idx2word = preprocess(corpus)\n",
    "print(f'Processed corpus: {processed_corpus} \\n word2idx: {word2idx} \\n idx2word: {idx2word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共現矩陣\n",
    "將轉化處理過的文本資料轉化為共現矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 1, 1],\n",
       "       [1, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 0, 1, 1, 2, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 2, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定義共現矩陣函式\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            for i in range(1, window_size+1):\n",
    "                left_idx = idx - i\n",
    "                right_idx = idx + i\n",
    "\n",
    "                if left_idx >= 0:\n",
    "                    left_word_id = sentence[left_idx]\n",
    "                    co_matrix[word_id, left_word_id] += 1\n",
    "\n",
    "                if right_idx < sentence_size:\n",
    "                    right_word_id = sentence[right_idx]\n",
    "                    co_matrix[word_id, right_word_id] += 1\n",
    "                \n",
    "    return co_matrix\n",
    "\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 1, 1],\n",
       "       [1, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 0, 1, 1, 2, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 1, 2, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義共現矩陣函式\n",
    "# method two\n",
    "\n",
    "def create_co_matrix(corpus: np.ndarray, vocab_size: int, window_size: int=1):\n",
    "    '''\n",
    "    '''\n",
    "    # initialize co-occurrence matrix\n",
    "    co_matrix = np.zeros(shape=(vocab_size, vocab_size), dtype=np.int32)\n",
    "    \n",
    "    for sentence in corpus:\n",
    "        sentence_size = len(sentence)\n",
    "    \n",
    "        for idx, word_id in enumerate(sentence):\n",
    "            left_idx = idx - window_size if idx - window_size >= 0 else 0\n",
    "            context_ids = sentence[left_idx:idx]\n",
    "            \n",
    "            for left_i, left_id in enumerate(context_ids):\n",
    "                co_matrix[word_id, left_id] += 1\n",
    "                co_matrix[left_id, word_id] += 1\n",
    "\n",
    "    return co_matrix\n",
    "\n",
    "co_matrix = create_co_matrix(processed_corpus, len(word2idx), 2)\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量間相似度\n",
    "比較轉換為向量的字詞的方法有很多種，其中當要表示字詞的相似度時，最常使用的方法為餘弦相似度 (Cosine Similarity)\n",
    "\n",
    "$$\n",
    "sim(x,y) = \\frac{xy}{||x||||y||}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7071067726510136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義餘弦相似度\n",
    "def cos_similarity(x: np.ndarray, y: np.ndarray, eps: float=1e-8):\n",
    "    nx = x / (np.sqrt(np.sum(x**2)) + eps)\n",
    "    ny = y / (np.sqrt(np.sum(y**2)) + eps)\n",
    "    \n",
    "    return np.dot(nx,ny)\n",
    "\n",
    "# calculate the similarity between I and you\n",
    "cos_similarity(co_matrix[word2idx['i']], co_matrix[word2idx['you']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立可供查詢相似度的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸入字詞，查詢與此字詞top_n相似的結果\n",
    "def top_k_similarity(query: str, word2idx: dict, idx2word: dict, word_matrix: np.ndarray, top_k: int=3):\n",
    "    # handle the situation of query word not in corpus\n",
    "    if query not in word2idx:\n",
    "        raise ValueError(f\"{query} is not found in input dictionary\")\n",
    "    \n",
    "    # handle the situation of top_k is the same as the amount of words\n",
    "    if top_k >= len(word2idx):\n",
    "        raise ValueError(f\"top_k needs to be less than the amount of words\")\n",
    "        \n",
    "    print(f\"[query] : {query}\")\n",
    "    query_id = word2idx[query]\n",
    "    query_vec = word_matrix[query_id]\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    similarity_scores = np.zeros(len(word2idx))\n",
    "    for i in range(len(word2idx)):\n",
    "        similarity_scores[i] = cos_similarity(query_vec, word_matrix[i])\n",
    "\n",
    "    # remove query word\n",
    "    similarity_scores[query_id] = 0\n",
    "    filter_word2idx = dict([(k, v) for k, v in word2idx.items() if k != query])\n",
    "    filter_idx2word = dict([(k, v) for k, v in idx2word.items() if k != query_id])\n",
    "    \n",
    "    # sorting by similarity score\n",
    "    top_k_idx = (-similarity_scores).argsort()[:top_k]\n",
    "    top_k_word = [filter_idx2word[word_idx] for word_idx in top_k_idx]\n",
    "    \n",
    "    return dict(zip(top_k_word, similarity_scores[top_k_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[query] : you\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'and': 0.8660253941251803, 'i': 0.7071067726510136, '.': 0.49999999292893216}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_similarity('you', word2idx, idx2word, co_matrix, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正向點間互資訊(PPMI)\n",
    "由於共生矩陣在高頻字上的缺陷，而PMI中加入了兩字詞共同出現的機率與各自出現的機率的關係，以此解決高頻詞在共生矩陣上的缺陷。\n",
    "而PPMI即將PMI內會產生負值的情況排除(若出現負值則賦予0)\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&PMI(x,y) = log_2\\frac{P(x,y)}{P(x)P(y)} = log_2\\frac{C(x,y)N}{C(x)C(y)} \\\\\n",
    "&PPMI(x,y) = max(0,PMI(x,y))\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義正向點間互資訊\n",
    "\n",
    "def ppmi(co_matrix: np.ndarray, eps: float=1e-8, verbose: bool=False):\n",
    "    M = np.zeros_like(co_matrix, dtype=np.float32)\n",
    "    N = np.sum(co_matrix)\n",
    "    S = np.sum(co_matrix, axis=0)\n",
    "    total = co_matrix.shape[0]*co_matrix.shape[1]\n",
    "\n",
    "    cnt = 0\n",
    "    \n",
    "    for i in range(co_matrix.shape[0]):\n",
    "        for j in range(co_matrix.shape[1]):\n",
    "            pmi = np.log2(co_matrix[i, j]*N / (S[i]*S[j] + eps))\n",
    "            M[i, j] = max(0, pmi)\n",
    "            \n",
    "            if verbose:\n",
    "                cnt += 1\n",
    "                if cnt % 10 == 0 or cnt == total:\n",
    "                    print(f\"{cnt}/{total} Done\")\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/49 Done\n",
      "20/49 Done\n",
      "30/49 Done\n",
      "40/49 Done\n",
      "49/49 Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/Documents/Coding/Python/Deep_Learning_Implement/Pytorch_Implementation/pytorch_env/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log2\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.       , 0.7004397, 0.       , 0.       , 0.       , 0.7004397,\n",
       "        1.7004397],\n",
       "       [0.7004397, 0.       , 0.       , 1.1154772, 0.       , 0.7004397,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.       , 0.3081223, 0.8930848, 0.8930848,\n",
       "        0.8930848],\n",
       "       [0.       , 1.1154772, 0.3081223, 0.       , 2.1154773, 0.       ,\n",
       "        0.       ],\n",
       "       [0.       , 0.       , 0.8930848, 2.1154773, 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [0.7004397, 0.7004397, 0.8930848, 0.       , 0.       , 0.       ,\n",
       "        0.       ],\n",
       "       [1.7004397, 0.       , 0.8930848, 0.       , 0.       , 0.       ,\n",
       "        0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ppmi = ppmi(co_matrix, verbose=True)\n",
    "output_ppmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD\n",
    "觀察上面的PPMI輸出矩陣，可以發現大部分的元素都為0(稀疏矩陣)，因此可以發現此矩陣包含了許多無法提供訊息的元素，利用奇異值分解，將矩陣降維，並保存重要的資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello in co-occurrence matrix: [0 1 1 0 1 0 0]\n",
      "hello in PPMI: [0.        1.1154772 0.3081223 0.        2.1154773 0.        0.       ]\n",
      "hello in SVD: [-0.5126197   0.5698161   0.39725903  0.4323913  -0.01054526 -0.124419\n",
      "  0.22839099]\n"
     ]
    }
   ],
   "source": [
    "# 使用np的linalg.svd對PPMI矩陣進行奇異值分解\n",
    "\n",
    "# SVD\n",
    "U, S, V = np.linalg.svd(output_ppmi)\n",
    "\n",
    "# 使用SVD將將原本的稀疏向量轉變為稠密向量\n",
    "print(f\"hello in co-occurrence matrix: {co_matrix[word2idx['hello']]}\")\n",
    "print(f\"hello in PPMI: {output_ppmi[word2idx['hello']]}\")\n",
    "print(f\"hello in SVD: {U[word2idx['hello']]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.8041792e-08  7.0043969e-01  5.6385137e-09 -7.4432329e-08\n",
      "  -6.8160695e-09  7.0043969e-01  1.7004398e+00]\n",
      " [ 7.0043969e-01  2.3153314e-08  2.2115112e-08  1.1154772e+00\n",
      "   2.0622537e-08  7.0043969e-01  3.5444103e-08]\n",
      " [ 4.0985121e-08  5.5780403e-09  1.0392343e-08  3.0812228e-01\n",
      "   8.9308482e-01  8.9308482e-01  8.9308482e-01]\n",
      " [-1.3404321e-08  1.1154772e+00  3.0812228e-01 -5.6422177e-08\n",
      "   2.1154773e+00 -4.2378574e-08 -6.0040975e-08]\n",
      " [-7.4080468e-08  2.2216554e-08  8.9308482e-01  2.1154773e+00\n",
      "  -3.3683197e-08 -8.4676607e-08 -4.0760728e-08]\n",
      " [ 7.0043969e-01  7.0043969e-01  8.9308482e-01 -4.3795090e-08\n",
      "  -8.3527041e-08 -2.3019233e-08 -4.4883759e-08]\n",
      " [ 1.7004397e+00  3.7209105e-08  8.9308476e-01 -4.3083389e-08\n",
      "  -4.8094705e-08  1.4502533e-09 -4.0341142e-08]]\n",
      "[[0.        0.7004397 0.        0.        0.        0.7004397 1.7004397]\n",
      " [0.7004397 0.        0.        1.1154772 0.        0.7004397 0.       ]\n",
      " [0.        0.        0.        0.3081223 0.8930848 0.8930848 0.8930848]\n",
      " [0.        1.1154772 0.3081223 0.        2.1154773 0.        0.       ]\n",
      " [0.        0.        0.8930848 2.1154773 0.        0.        0.       ]\n",
      " [0.7004397 0.7004397 0.8930848 0.        0.        0.        0.       ]\n",
      " [1.7004397 0.        0.8930848 0.        0.        0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "# 檢查分解是否正確\n",
    "A = U @ np.diag(S) @ V\n",
    "print(A)\n",
    "print(output_ppmi)\n",
    "# 可以發先做完SVD得結果跟原來的output_ppmi是相同的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.9371588  2.5547988  2.1101685  1.9556583  1.1257027  0.58972406\n",
      " 0.30812874]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.31352073,  0.30776063, -0.48896635, -0.5457005 , -0.38465765,\n",
       "        -0.12412582],\n",
       "       [-0.33312967, -0.30777904, -0.16466641, -0.03673923,  0.5294517 ,\n",
       "        -0.6964652 ],\n",
       "       [-0.3710324 ,  0.26495245, -0.31999645, -0.0807369 ,  0.45295563,\n",
       "         0.4691856 ],\n",
       "       [-0.5126197 ,  0.5698161 ,  0.39725903,  0.4323913 , -0.01054526,\n",
       "        -0.124419  ],\n",
       "       [-0.48203   , -0.56445074, -0.26282662,  0.430857  , -0.33953863,\n",
       "         0.2642201 ],\n",
       "       [-0.26702777, -0.09261478,  0.3523957 , -0.24547683, -0.44945022,\n",
       "        -0.26410997],\n",
       "       [-0.29432744, -0.29746115,  0.5294562 , -0.511355  ,  0.22169203,\n",
       "         0.35262936]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以發現前六個奇異值就佔了絕大多數的奇異值\n",
    "print(S)\n",
    "\n",
    "# 可以取前六個維度當作降為的詞向量\n",
    "U_reduce = U[:, 0:6]\n",
    "U_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 將詞向量降為二維方便視覺化\n",
    "U_visualization = U[:, 0:2]\n",
    "\n",
    "# visualization\n",
    "for word, word_id in word2idx.items():\n",
    "    plt.annotate(word, (U_reduce[word_id, 0], U_reduce[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U_reduce[:, 0], U_reduce[:, 1], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
