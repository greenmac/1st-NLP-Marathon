{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手刻基本Naive Bayes模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 學習重點：理解單純貝氏模型原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import glob\n",
    "import codecs\n",
    "\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(message):\n",
    "    message=message.lower()\n",
    "    all_words=re.findall(\"[a-z0-9]+\",message)\n",
    "    return set(all_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀入資料並分割為 train/testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "paths =[r'../data/spam_data/spam', r'../data/spam_data/easy_ham', r'../data/spam_data/hard_ham'] \n",
    "for path in paths:\n",
    "    for fn in glob.glob(path+\"/*\"):\n",
    "        if \"ham\" not in fn:\n",
    "            is_spam = True\n",
    "        else:\n",
    "            is_spam = False\n",
    "        #codecs.open可以避開錯誤，用errors='ignore'\n",
    "        with codecs.open(fn,encoding='utf-8', errors='ignore') as file:\n",
    "            for line in file:\n",
    "                #這個line的開頭為Subject:\n",
    "                if line.startswith(\"Subject:\"):\n",
    "                    subject=re.sub(r\"^Subject:\",\"\",line).strip()\n",
    "                    X.append(subject)\n",
    "                    Y.append(is_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# random_state 是為了讓各為學員得到相同的結果，平時可以移除\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for x_, y_ in zip(X_train, y_train):\n",
    "    train_data.append([x_, y_])\n",
    "\n",
    "for x_, y_ in zip(X_test, y_test):\n",
    "    test_data.append([x_, y_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defaultdict用法示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dic : defaultdict(<function <lambda> at 0x000001AD440AF700>, {'you': [1, 0], 'hi': [1, 2], 'no': [8, 1]})\nyou : [1, 0]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "mess='This is our first time in Taiwan,,,,, such a beautiful contury'\n",
    "\n",
    "counts=defaultdict(lambda:[0,0])\n",
    "counts['you'][0]+=1\n",
    "counts['hi'][0]+=1\n",
    "counts['hi'][1]+=2\n",
    "counts['no'][1]+=1\n",
    "counts['no'][0]+=8\n",
    "print('dic : {}'.format(counts))\n",
    "print('you : {}'.format(counts['you']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 創造一個字典，裡面是{'hi': [1, 0]}，對應第一個數字是是垃圾郵件的次數，對應第二個數字是不是垃圾郵件的次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(training_set):\n",
    "    counts=defaultdict(lambda:[0,0])\n",
    "    for message,is_spam in training_set:\n",
    "        for word in tokenize(message):\n",
    "            '''自行填入， list[0]為出現在spam中的次數，list[1]為出現在ham(非spam)中的次數'''\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算 p(w|spam) / p(w|non_spam)\n",
    "* 其中K為超參數，為了確保分母/分子皆不為0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_probabilities(counts,total_spams,total_non_spams,k=0.5):\n",
    "    #獲得三組數據，分別為w這個字，p(w|spam)，p(w|non_spam)\n",
    "    #counts[w][0]=spam,counts[w][1]=non_spam\n",
    "    return [(w,(\"自行填入\"+k)/(\"自行填入\"+2*k),(\"自行填入\"+k)/(\"自行填入\"+2*k)) for w in counts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算貝氏結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spam_probability(word_probs,message, is_spam_probability, is_not_spam_probability):\n",
    "    #先把這個mail的文字處理一下\n",
    "    message_words=tokenize(message)\n",
    "    #初始化值\n",
    "    log_prob_if_spam=log_prob_if_not_spam=0.0\n",
    "    #將w這個字，p(w|spam)，p(w|non_spam)依序引入\n",
    "    for word,prob_if_spam,prob_if_not_spam in word_probs:\n",
    "        if word in message_words:\n",
    "            #假如這個字有在這個mail中出現\n",
    "            #把他的p(w|spam)轉log值加上log_prob_if_spam\n",
    "            log_prob_if_spam=\"自行填入\"\n",
    "            #把他的p(w|non_spam)轉log值加上log_prob_if_not_spam\n",
    "            log_prob_if_not_spam=\"自行填入\"\n",
    "        else:\n",
    "            #如果沒出現log_prob_if_spam➕上得值就是1-p(w|spam)也就是這封信是垃圾郵件但是w這個字卻沒在裡面\n",
    "            log_prob_if_spam=log_prob_if_spam+math.log(1-prob_if_spam)\n",
    "            log_prob_if_not_spam=log_prob_if_not_spam+math.log(1-prob_if_not_spam)\n",
    "    log_prob_if_spam = log_prob_if_spam + \"自行填入\"\n",
    "    log_prob_if_not_spam = log_prob_if_not_spam + \"自行填入\"\n",
    "    \n",
    "    #把+起來的值轉成exp再算NaiveBayes\n",
    "    prob_if_spam=\"自行填入\"\n",
    "    prob_if_not_spam=\"自行填入\"\n",
    "    #貝氏\n",
    "    return prob_if_spam/(prob_if_spam+prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 打包整個模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self,k=0.5):\n",
    "        self.k=k\n",
    "        self.word_probs=[]\n",
    "    def train(self,training_set):\n",
    "        #訓練的資料格式為(message,is_spam)\n",
    "        #所有垃圾郵件的數量\n",
    "        num_spams=len([is_spam for message,is_spam in training_set if is_spam])\n",
    "        #所有不是垃圾郵件的數量\n",
    "        num_non_spams=len(training_set)-num_spams\n",
    "        \n",
    "        self.is_spam_probability = \"自行填入\"\n",
    "        self.is_not_spam_probability = \"自行填入\"\n",
    "        #把training_set裡面的所有字體轉成('Bad',num_is_spam,num_not_spam)\n",
    "        word_counts=count_words(training_set)\n",
    "        self.word_probs=word_probabilities(word_counts,num_spams,num_non_spams,self.k)\n",
    "    def classify(self,message):\n",
    "        return spam_probability(self.word_probs,message, self.is_spam_probability, self.is_not_spam_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit 訓練集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=NaiveBayesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.train(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7731a8a99998>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassified\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_spam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_spam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_spam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspam_probability\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_spam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspam_probability\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassified\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-7731a8a99998>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclassified\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_spam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msubject\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_spam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_spam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspam_probability\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_spam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mspam_probability\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassified\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-295cbe8eb904>\u001b[0m in \u001b[0;36mclassify\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_probs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_counts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_spams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_non_spams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mspam_probability\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_probs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_spam_probability\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_not_spam_probability\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-3aed0a9a1a9b>\u001b[0m in \u001b[0;36mspam_probability\u001b[1;34m(word_probs, message, is_spam_probability, is_not_spam_probability)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mlog_prob_if_spam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_prob_if_spam\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mprob_if_spam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mlog_prob_if_not_spam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_prob_if_not_spam\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mprob_if_not_spam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mlog_prob_if_spam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_prob_if_spam\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"自行填入\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mlog_prob_if_not_spam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_prob_if_not_spam\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"自行填入\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "\n",
    "classified=[(subject,is_spam,classifier.classify(subject)) for subject,is_spam in test_data]\n",
    "counts=Counter((is_spam,spam_probability>0.5) for _,is_spam,spam_probability in classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'you': [1, 0], 'hi': [1, 2], 'no': [8, 1]})"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 92.70%\n",
      "precision : 86.36%\n",
      "recall : 58.16%\n"
     ]
    }
   ],
   "source": [
    "precision=counts[(True, True)]/(counts[(True, True)]+counts[(False, True)])\n",
    "recall=counts[(True, True)]/(counts[(True, True)]+counts[(True, False)])\n",
    "binary_accuracy = (counts[(True, True)]+counts[(False, False)])/(counts[(False, True)]+counts[(False, False)]+counts[(True, True)]+counts[(True, False)])\n",
    "print('accuracy : {:.2f}%'.format(binary_accuracy*100))\n",
    "print('precision : {:.2f}%'.format(precision*100))\n",
    "print('recall : {:.2f}%'.format(recall*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "interpreter": {
   "hash": "b071336fb10f883fe7257e8e92e9c59e797cbbef23e0f498fe46632596d585c7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}