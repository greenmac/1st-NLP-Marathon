1.目前斷詞的主流方法有以下幾種:
    ．基於詞典的分詞法：按照一定的策略將待匹配的字符串和一個已建立好的 “充分大的” 詞典中的詞進行匹配
    ．基於統計的機器學習算法：HMM(隱藏式馬可夫模型)，CRF (Conditional Random Field)，SVM，etc.
    ．基於深度學習的算法：雙向 LSTM 模型

2.
    ．jieba.cut方法接受两个输入参数: 1) 第一个参数为需要分词的字符串 2）cut_all参数用来控制是否采用全模式
    ．jieba.cut_for_search方法接受一个参数：需要分词的字符串,该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细

3.结巴分词0.4版本以上支持四种分词模式：
    ．精确模式：试图将句子最精确地切开，适合文本分析；
    ．全模式：把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义
    ．搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词
    ．paddle模式：利用PaddlePaddle深度学习框架，训练序列标注（双向GRU）网络模型实现分词。同时支持词性标注。（应该是百度提供的分词模型）
